
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-171431390-1"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-SPY7S5B91F"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-171431390-1');
    </script>

    <!-- Base File Includes -->
    
    

    <!-- Includes -->
    
    <!-- Code highlighting
        To Use: <pre><code class="language-python">print('Hello World')</code></pre>
    -->
    <link rel="stylesheet" href="/static/home/packages/highlightjs/dracula.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <!-- LaTeX input. Use \(...\) for inline mathematics and $$...$$ or \[...\] for block equations -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


    <!-- Title -->
    <title>
            DRC
        
    - Learn Keras - Layers

    </title>
    <!-- ### Bootstrap Files ### -->
    <!-- Fit device screen size -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    <!-- ### END BOOTSTRAP FILES ### -->
	
	<!-- Font Awesome 4 -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Load Custom Bootstrap CSS -->
    <link rel="stylesheet" type="text/css" href="/static/home/bootstrap.css">

    <!-- Favicon -->
    <link rel="shortcut icon" type="image/png" href="/static/home/images/favicon.ico">

    <!-- Hide/Reveal Navbar Upon Scrolling -->
    <script src="/static/home/js/navbar_show.js" async></script>
    <link rel="stylesheet" type="text/css" href="/static/home/css/navbar.css">

    <!-- Javascript to run after the page has loaded -->
    <script src="/static/home/js/on_page_load.js" defer></script>
    
</head>

<!-- Body -->
<body class='bg-light'>
    <!-- Navigation Bar -->
    <header class="nav-down">
        <nav class="navbar py-0 navbar-expand-md navbar-dark bg-dark">
    <!-- Website Brand Icon -->
    <a class="navbar-brand" href="/">DRC</a>
    <!-- Menu Button when screen is small -->
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <!-- Navigation Buttons -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
            <!-- Home -->
            <li class="nav-item dropdown">
                <!-- Screen Reader -->
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/">Home</a>
                </div>
            </li>
            <!-- Experience -->
            <li class="nav-item dropdown">
                <!-- Screen Reader -->
                
                <!-- Experience Types -->
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/resume/">Experience</a>
                    <button type="button" class="btn btn-dark px-1 dropdown-toggle dropdown-toggle-split" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        <span class="sr-only">Toggle Dropdown</span>
                    </button>
                    <div class="dropdown-menu py-0 bg-secondary">
                        <a class="dropdown-item" href="/resume/">&#8226; Resume</a>
                        <a class="dropdown-item text-white" href="/work-experience/">&#8226; Work Experience</a>
                        <!-- <a class="dropdown-item text-white" href="/computer-skills/">&#8226; Computer Skills</a> -->
                    </div>
                </div>
            </li>
 
            <!-- Blog Posts -->
<!--            <li class="nav-item dropdown">
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/blog/">Blog</a>
                    <button type="button" class="btn btn-dark px-1 dropdown-toggle dropdown-toggle-split" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        <span class="sr-only">Toggle Dropdown</span>
                    </button>
                    <div class="dropdown-menu py-0 bg-secondary">
                        <a class="dropdown-item" href="/blog/project/">&#8226; Projects</a>
                        <a class="dropdown-item" href="/blog/tutorial/">&#8226; Tutorials</a>
                        <a class="dropdown-item" href="#">&#8226; Other</a>
                    </div>
                </div>
            </li>
-->        
            <!-- Research -->
            <li class="nav-item dropdown">
                <!-- Screen Reader -->
                
                <!-- Experience Types -->
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/research/">Research</a>
                    <button type="button" class="btn btn-dark px-1 dropdown-toggle dropdown-toggle-split" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        <span class="sr-only">Toggle Dropdown</span>
                    </button>
                    <div class="dropdown-menu active py-0 bg-secondary">
                        <a class="dropdown-item" href="/research/papers/">&#8226; Papers</a>
                        <a class="dropdown-item" href="/research/projects/">&#8226; Projects</a>
                        <a class="dropdown-item" href="/research/notes/">&#8226; Notes</a>
                    </div>
                </div>
            </li>
            <!-- Learn -->
            <li class="nav-item dropdown">
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/learn/">Learn</a>
                </div>
            </li>
            <!-- Projects -->
            <li class="nav-item dropdown">
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/projects/">Projects</a>
                </div>
            </li>
            <!-- Write-Ups -->
            <li class="nav-item dropdown">
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/writeups/kattis/">Write-Ups</a>
                </div>
            </li>
            <!-- About -->
            <li class="nav-item dropdown">
                <!-- Screen Reader -->
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/about/">About</a>
                </div>
            </li>
            <!-- Contact -->
            <li class="nav-item dropdown">
                <!-- Screen Reader -->
                
                <div class="btn-group ">
                    <a class="nav-link btn btn-dark pr-1" href="/contact/">Contact</a>
                </div>
            </li>
        </ul>
        <!-- Search  bar -->
        <form class="form-inline my-1" action="/search/">
            <input class="form-control mr-0" style="font-size:14px; width:85%;" type="search" placeholder="Search" aria-label="Search" name="q" autocomplete="on">
            <button type="submit" style="width:15%; background-color: Transparent; border-color: Transparent;">
                <i class="fa fa-search" style="font-size:18px; color:#FFFFFF;"></i>
            </button>
        </form>
    </div>
</nav>

    </header>

    <!-- Content -->
    <div style="margin-top:60px;">
        <div class="container rounded m-4 mx-auto p-4 bg-white shadow-lg">
            
<div class="row">
    <!-- Scroll Bar -->
    <div class="d-none d-xl-block col-xl-2 overflow-auto" style="position:relative; overflow-y:scroll; height:80vh">
        <div id="side-navbar" class="list-group flex-xl-column flex-row">
            <center>
                <a class="list-group-item list-group-item-action" href="#layers">
                    Layers
                </a>
            </center>
            
                <a class="list-group-item list-group-item-action" href="#activation-functions">
                    Activation Functions
                </a>
            
                <a class="list-group-item list-group-item-action" href="#attention-layers">
                    Attention Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#base-layer-class">
                    Base Layer Class
                </a>
            
                <a class="list-group-item list-group-item-action" href="#convolutional-layers">
                    Convolutional Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#core-layers">
                    Core Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#locally-connected-layers">
                    Locally Connected Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#merging-layers">
                    Merging Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#normalization-layers">
                    Normalization Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#pooling-layers">
                    Pooling Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#preprocessing-layers">
                    Preprocessing Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#recurrent-layers">
                    Recurrent Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#reshaping-layers">
                    Reshaping Layers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#weight-contraints">
                    Weight Contraints
                </a>
            
                <a class="list-group-item list-group-item-action" href="#weight-initializers">
                    Weight Initializers
                </a>
            
                <a class="list-group-item list-group-item-action" href="#weight-regularizers">
                    Weight Regularizers
                </a>
            
        </div>
    </div>
   <!-- Content -->
   <div class="col" data-spy="scroll" data-target="#side-navbar" class="scrollspy" style="position:relative; overflow-y:scroll; height:80vh">
       <!-- Subject Information -->
       <div class="d-flex justify-content-between">
           <a href="/learn/keras/"><button type="button" class="btn btn-light">Back</button></a>
           <h1 id='layers'>
               Keras - Layers
           </h1>
           <br/>
       </div>
        <p>A model is made up of multiple <a href="https://keras.io/api/layers/" target="_blank">layers</a>.<!-- A layer has at least three components, a layer type, shape, and activation function. Under-the-hood, a layer is just a set of weights --></p>

        <!-- For each topic -->
        
            <!-- Topic header -->
            <h2 id="activation-functions"><a href="/learn/keras/layers/activation-functions/">Activation Functions</a></h2>
            <!-- Include topic -->
            <p>The <a href="https://keras.io/api/layers/activations/" target="_blank">activation function</a> determines what is outputted by neurons of this layer. There are two ways to add an activation function to a layer. You can either add it via the <code>activation</code> argument on any layer or you can add the activation function as a layer.</p>

<ul>
    <li>Argument:</li>
</ul>

<pre class="rounded"><code class="python">model.add(keras.layers.Dense(32, activation='relu'))</code></pre>

<ul>
    <li>As a layer:</li>
</ul>

<pre class="rounded"><code class="python">model.add(keras.layers.Dense(32))
model.add(keras.layers.Activation('relu'))</code></pre>

<p>Built in activation functions:</p>

<ul>
    <li>relu</li>
    <ul>
        <li>The ReLU or rectified linear unit activation function: <code>max(x, 0)</code></li>
        <li>Is the generic activation function.</li>
        <li>To clip, you can set the max value using the <code>max_value</code> argument or the min value using the <code>threshold</code> argument.</li>
    </ul>
    <li>sigmoid</li>
    <ul>
        <li>\( \theta (x) = \frac{1}{1 + e^{-x}} \)</li>
        <li>Values are between 0 and 1</li>
        <li>S-Shaped</li>
        <li>Great for making the last layer output a probability.</li>
    </ul>
    <li>softmax</li>
    <ul>
        <li>Converts a real vector to a vector of categorical probabilities.</li>
        <li>Each output is the probability of that output. All outputs sum to 1.</li>
        <li>Generally used as the activation function for the <i>last layer</i>.</li>
    </ul>
    <li>softplus</li>
    <ul>
        <li>\( softplus(x) = log(e^x + 1) \)</li>
    </ul>
    <li>softsign</li>
    <ul>
        <li>\( softsign(x) = \frac{x}{\lvert x \rvert + 1} \)</li>
    </ul>
    <li>tanh</li>
    <ul>
        <li>Hyperbolic tangent. \( tanh(x) = \frac{sinh(x)}{cosh(x)} = \frac{e^x - e^{-x}}{e^x + e^{-x}} \)</li>
        <li>Outputs are between (-1, 1)</li>
        <li>S-Shaped</li>
        <li>Advantages: &bull;Negative numbers are perserved &bull;Zero inputs are mapped near zero</li>
    </ul>
    <li>selu</li>
    <ul>
        <li>The SELU or scaled exponential linear unit is related to the ReLU activation function and super related to the Leaky ReLU activation function.</li>
        <ul>
            <li><code>if x &ge; 0: return scale * x</code></li>
            <li><code>if x &le; 0: return scale * alpha * (exp(x) - 1)</code></li>
        </ul>
        <li>Unlike ReLU, SELU allows negative values, so these cells cannot die (all become 0).</li>
        <li>Compared to leaky ReLU, there is an exponential dip instead of a straight line for negative values.</li>
    </ul>
    <li>elu</li>
    <ul>
        <li>Exponential Linear Unit. SELU, but without the scale.</li>
    </ul>
    <li>exponential</li>
</ul>

<p>Advanced Activation Functions:</p>
<ul>
    <li>LeakyReLU</li>
    <ul>
        <li><code>tf.keras.layers.LeackyReLU(alpha=0.3)</code></li>
        <li>Like exponential linear unit, but negative values are a linear line with a slight slope.</li>
    </ul>
</ul>

<p>Pros and Cons of most activation function: <a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank">HERE</a>.</p>

        
            <!-- Topic header -->
            <h2 id="attention-layers"><a href="/learn/keras/layers/attention-layers/">Attention Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="base-layer-class"><a href="/learn/keras/layers/base-layer-class/">Base Layer Class</a></h2>
            <!-- Include topic -->
            <p>All layers inherit from the <a href="https://keras.io/api/layers/base_layer/" target="_blank">base layer</a> class.</p>

<pre class="rounded"><code class="python">tf.keras.layers.Layer(
    trainable=True, name=None, dtype=None, dynamic=False, **kwargs   
)</code></pre>

<ul>
    <li>Trainable: If false, the layer is <i>frozen</i> and will not be trained.</li>
    <li>Name: Name a layer. Can be accessed via <code>model.layers[0].name</code></li>
</ul>

        
            <!-- Topic header -->
            <h2 id="convolutional-layers"><a href="/learn/keras/layers/convolutional-layers/">Convolutional Layers</a></h2>
            <!-- Include topic -->
            <p>Convolutional layers are used with convolutional neural networks (CNNs)</p>

<h5>Conv*D</h5>
<p>There are three different convolutional layer dimensions:</p>

<ul>
    <li><a href="https://keras.io/api/layers/convolution_layers/convolution1d/" target="_blank">Conv1D</a>: Ex temporal convolutions</li>
    <li><a href="https://keras.io/api/layers/convolution_layers/convolution2d/" target="_blank">Conv2D</a>: Ex spatial convolutions over images</li>
    <li><a href="https://keras.io/api/layers/convolution_layers/convolution3d/" target="_blank">Conv3D</a>: Ex spatial convolutions over volumes</li>
</ul>

<pre class="rounded"><code class="python">tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding="valid",
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer="glorot_uniform",
    bias_initializer="zeros",
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)</code></pre>

<ul>
    <li>Filters: Number of output filers</li>
    <li>Kernel Size: Height and width of the 2D convolutional window. Tuple of ints</li>
    <li>Strides: Specifies the strides (movement of the window) along the height and width.</li>
    <li>Padding:</li>
    <ul>
        <li>'valid': No padding. Output shape will be smaller than input shape</li>
        <li>'same': Adds padding. Output shape (height/width, not channels/filters) will be the same as the input</li>
    </ul>
    <li>data_format</li>
    <ul>
        <li>'channels_last' (default): Expects <code>(batch_size, height, width, channels)</code> as input</li>
        <li>'channels_first': Expects <code>(batch_size, channels, height, width)</code> as input</li>
    </ul>
</ul>

<p>Input Shape: <code>batch_shape + (channels, rows, cols)</code> if data format is channels first</p>
<p>Output Shape: <code>batch_shape + (filters, new_rows, new_cols)</code> if data format is channels first. Rows and columns may change due to padding.</p>


<h5>SeperableConv*D</h5>
<p>Similar to Conv*D layers, but channels are kept separate at first and then mixed at the end. The 2D version is similar to an Inception Block.</p>
<ul>
    <li><a href="https://keras.io/api/layers/convolution_layers/separable_convolution1d/" target="_blank">SeparableConv1D</a></li>
    <li><a href="https://keras.io/api/layers/convolution_layers/separable_convolution2d/" target="_blank">SeparableConv2D</a></li>
</ul>

<h5><a href="https://keras.io/api/layers/convolution_layers/depthwise_convolution2d/" target="_blank"></a>DepthwiseConv2D</h5>
<p>Performs the first half of SeperableConv2D, where channels are kept separate.</p>

<h5>Conv*DTranspose (Deconvolution)</h5>
<p>"Undoes" a convolutional layer. Is generally used to increase the dimensionality (rows and columns) while decreasing the channel number.</p>
<ul>
    <li><a href="https://keras.io/api/layers/convolution_layers/convolution2d_transpose/" target="_blank">Conv2DTranspose</a></li>
    <li><a href="https://keras.io/api/layers/convolution_layers/convolution3d_transpose/" target="_blank">Conv3DTranspose</a></li>
</ul>

<pre class="rounded"><code class="python">tf.keras.layers.Conv2DTranspose(
    filters,
    kernel_size,
    strides=(1, 1),
    padding="valid",
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer="glorot_uniform",
    bias_initializer="zeros",
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)</code></pre>


        
            <!-- Topic header -->
            <h2 id="core-layers"><a href="/learn/keras/layers/core-layers/">Core Layers</a></h2>
            <!-- Include topic -->
            <p></p>

<h5><a href="https://keras.io/api/layers/core_layers/input/">Input</a></h5>
<p>Used to instantiate a keras tensor</p>
<pre class="rounded"><code class="python">tf.keras.Input(
    shape=None,
    batch_size=None,
    name=None,
    dtype=None,
    sparse=False,
    tensor=None,
    ragged=False,
    **kwargs
)</code></pre>
<ul>
    <li>Shape: Input shape, not including batch size. Should be a tuple of integers.</li>
</ul>

<h5><a href="https://keras.io/api/layers/core_layers/dense/" target=_blank>Dense</a></h5>
<p>The most common layer type. A layer that is completely connected to the previous layer.</p>
<pre class="rounded"><code class="python">tf.keras.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer="glorot_uniform",
    bias_initializer="zeros",
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)</code></pre>
<ul>
    <li>Units: The number of neurons</li>
</ul>

<h5><a href="https://keras.io/api/layers/core_layers/activation/" target="_blank">Activation</a></h5>
<p>Add an activation function to the previous layer.</p>
<pre class="rounded"><code class="python">tf.keras.layers.Activation(activation, **kwargs)</code></pre>

<h5><a href="https://keras.io/api/layers/core_layers/embedding/" target="_blank">Embedding</a></h5>
<p><a href="https://gdcoder.com/what-is-an-embedding-layer/" target="_blank">THIS</a> site does a great job of explaining what an embedding layer does. "an embedding learns tries to find the optimal mapping of each of the unique words to a vector of real numbers. The size of that vectors is equal to the output_dim". An embedding layer maps a vector that consists of a small sample of the vocabulary to a feature vector.</p>
<p>Must be the first layer of a model.</p>
<pre class="rounded"><code class="python">tf.keras.layers.Embedding(
    input_dim,
    output_dim,
    embeddings_initializer="uniform",
    embeddings_regularizer=None,
    activity_regularizer=None,
    embeddings_constraint=None,
    mask_zero=False,
    input_length=None,
    **kwargs
)</code></pre>
<ul>
    <li>Input Dim: Vocabulary size, number of possible unique words in an input vector.</li>
    <li>Output Dim: Dimension of the dense embedding (size of the feature vector for each unique word)</li>
    <li>Input Length: Use if the input is of a constant length. Required if using <code>Flatten</code> followed by <code>Dense</code> later on.</li>
</ul>

<h5><a href="https://keras.io/api/layers/core_layers/masking/" target="_blank">Masking</a></h5>
<p>Used primarily in RNNs. Skips timesteps. Good for skipping padding when using LSTM.</p>
<pre class="rounded"><code class="python">tf.keras.layers.Masking(mask_value=0.0, **kwargs)</code></pre>

<h5><a href="https://keras.io/api/layers/core_layers/lambda/" target="_blank">Lambda</a></h5>
<pre class="rounded"><code class="python">tf.keras.layers.Lambda(
    function, output_shape=None, mask=None, arguments=None, **kwargs
)</code></pre>
<ul>
    <li>Function: Lambda function</li>
</ul>

        
            <!-- Topic header -->
            <h2 id="locally-connected-layers"><a href="/learn/keras/layers/locally-connected-layers/">Locally Connected Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="merging-layers"><a href="/learn/keras/layers/merging-layers/">Merging Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="normalization-layers"><a href="/learn/keras/layers/normalization-layers/">Normalization Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="pooling-layers"><a href="/learn/keras/layers/pooling-layers/">Pooling Layers</a></h2>
            <!-- Include topic -->
            <p>Pooling layers are used to downsample. They are generally used with convolutional layers to reduce the size of the feature space</p>

<h5>MaxPooling*D</h5>
<p>Max pooling uses passes the max value over a window to the next layer. There are three different pooling layer dimensions:</p>

<ul>
    <li><a href="https://keras.io/api/layers/pooling_layers/max_pooling1d/" target="_blank">Conv1D</a>: Ex: temporal data</li>
    <li><a href="https://keras.io/api/layers/pooling_layers/max_pooling2d/" target="_blank">Conv2D</a>: Ex spatial data (images)</li>
    <li><a href="https://keras.io/api/layers/pooling_layers/max_pooling3d/" target="_blank">Conv3D</a>: Ex 3D data (spatial or spatio-temporal)</li>
</ul>

<pre class="rounded"><code class="python">tf.keras.layers.MaxPooling2D(
    pool_size=(2, 2), 
    strides=None, 
    padding="valid", 
    data_format=None, 
    **kwargs
)</code></pre>

<ul>
    <li>Pool Size: Size of the window</li>
    <li>Strides: How far the window moves after each pooling step (int or tuple of ints)</li>
    <li>Padding:</li>
    <ul>
        <li>'valid': No padding. <code>output_shape = (input_shape - pool_size + 1) / strides)</code></li>
        <li>'same': Output will have the same height/width dimensions as input. <code>output_shape = input_shape / strides</code></li>
    </ul>
    <li>Data Format: 'channels_last' or 'channels_first'</li>
</ul>

<h5>AveragePooling*D</h5>
<p>Average pooling passes the average value over a window to the next layer. There are three different pooling layer dimensions:</p>

<ul>
    <li><a href="https://keras.io/api/layers/pooling_layers/average_pooling1d/" target="_blank">AveragePooling1D</a>: Ex: temporal data</li>
    <li><a href="https://keras.io/api/layers/pooling_layers/average_pooling2d/" target="_blank">AveragePooling2D</a>: Ex: spatial data (images)</li>
    <li><a href="https://keras.io/api/layers/pooling_layers/average_pooling3d/" target="_blank">AveragePooling3D</a>: Ex: 3D data (spatial or spatio-temporal)</li>
</ul>

<pre class="rounded"><code class="python">tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2), strides=None, padding="valid", data_format=None, **kwargs
)</code></pre>

<p>Args same as MaxPooling</p>

<h5>Other</h5>
<p>There are also <a href="https://keras.io/api/layers/pooling_layers/global_max_pooling2d/" target="_blank">GlobalMaxPooling</a> and <a href="https://keras.io/api/layers/pooling_layers/global_average_pooling2d/" target="_blank">GlobalAveragePooling</a> varients that don't use a window, but the entire input.</p>

        
            <!-- Topic header -->
            <h2 id="preprocessing-layers"><a href="/learn/keras/layers/preprocessing-layers/">Preprocessing Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="recurrent-layers"><a href="/learn/keras/layers/recurrent-layers/">Recurrent Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="reshaping-layers"><a href="/learn/keras/layers/reshaping-layers/">Reshaping Layers</a></h2>
            <!-- Include topic -->
            
        
            <!-- Topic header -->
            <h2 id="weight-contraints"><a href="/learn/keras/layers/weight-contraints/">Weight Contraints</a></h2>
            <!-- Include topic -->
            <p><a href="https://keras.io/api/layers/constraints/" target="_blank">Constraints</a> can be added to the weights of a layer. For example, a constraint might not allow negative weights or a constraint might limit the norm of a layer.</p>

        
            <!-- Topic header -->
            <h2 id="weight-initializers"><a href="/learn/keras/layers/weight-initializers/">Weight Initializers</a></h2>
            <!-- Include topic -->
            <p><a href="https://keras.io/api/layers/initializers/" target="_blank">Weight initalizers</a> initialize a layer's weights.</p>

        
            <!-- Topic header -->
            <h2 id="weight-regularizers"><a href="/learn/keras/layers/weight-regularizers/">Weight Regularizers</a></h2>
            <!-- Include topic -->
            <p><a href="https://keras.io/api/layers/regularizers/" target="_blank">Weight regularizers</a> penalizes certain aspects of a layer's parameters during optimization (training).</p>

<p>Three common regulaizers exist for most layer types:</p>
<ul>
    <li><code>kernel_regularizer</code>: Applies regularization function to the weights matrix</li>
    <li><code>bias_regularizer</code>: Applies regularization function to the bias</li>
    <li><code>activity_regularizer</code>: Applies regularization function to the output of the layer</li>
</ul>

<p>Good stackexchange <a href="https://stats.stackexchange.com/questions/383310/what-is-the-difference-between-kernel-bias-and-activity-regulizers-and-when-t" target="_blank">post</a> about the three regularizers.</p>

<p>There are three available regularizers:</p>
<ul>
    <li><code>tf.keras.regularizers.l1(l1=0.01)</code>: <code>loss = l1 * reduced_sum(abs(x))</code></li>
    <li><code>tf.keras.regularizers.l2(l1=0.01)</code>: <code>loss = l1 * reduced_sum(square(x))</code></li>
    <li><code>tf.keras.regularizers.l1_l2(l1=0.01, l2=0.02)</code></li>
</ul>

<p>For example:</p>
<pre class="rounded"><code class="python">layer = tf.keras.layers.Dense(
    units=64,
    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),
    bias_regularizer=regularizers.l2(1e-4),
    activity_regularizer=regularizers.l2(1e-5)
)</code></pre>

        
    </div>
</div>

        </div>
    </div>

    <!-- Footer -->
    <footer class="small text-center text-muted">
        <!-- Social Links -->
		<p>
            <a href="https://github.com/DaltonCole" target="_blank" class="fa fa-github" style="font-size:28px;color:black;"></a>
            &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/daltoncole1/" target="_blank" class="fa fa-linkedin" style="font-size:28px;color:#2867B2;"></a>
        </p>

        <!-- Copyright -->
        
        <p class="copyright"> Copyright &copy; 2020 
            -2024 
         | Dalton Russell Cole</p>

        <!-- Extra Footer Block -->
        
        
    </footer>
</body>
</html>
